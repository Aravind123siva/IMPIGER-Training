{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6beadc0f-de59-4895-bac0-e80c9da956bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: /home/aravinds/directory_env/video.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aravinds/directory_env/AIML_POC/lib/python3.10/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Transcription ---\n",
      "  Make your public speaking instantly better than everybody else. Now imagine if I started like this, hey, today I'm going to talk about my subject and I feel very excited about it. You're already bored. You're not paying attention. You're just going to take your phone out and start scrolling. So one thing you want to do is look at the audience. In this case, I'm looking at the camera. You want to have a more powerful voice and most importantly, you want to show enthusiasm for the topic you're talking about. Hey everyone, today we're going to be talking about public speaking. I want to teach you all the different ways where I've been able to develop my public speaking skills.\n",
      "\n",
      "--- Translated Text ---\n",
      " உங்கள் பொது பேசுவதை எல்லோரையும் விட உடனடியாக சிறப்பாக ஆக்குங்கள்.இப்போது நான் இப்படி தொடங்கினால் கற்பனை செய்து பாருங்கள், ஏய், இன்று நான் எனது விஷயத்தைப் பற்றி பேசப் போகிறேன், அதைப் பற்றி நான் மிகவும் உற்சாகமாக உணர்கிறேன்.நீங்கள் ஏற்கனவே சலித்துவிட்டீர்கள்.நீங்கள் கவனம் செலுத்தவில்லை.நீங்கள் உங்கள் தொலைபேசியை வெளியே எடுத்து ஸ்க்ரோலிங் செய்யத் தொடங்குவீர்கள்.எனவே நீங்கள் செய்ய விரும்பும் ஒரு விஷயம் பார்வையாளர்களைப் பார்ப்பது.இந்த விஷயத்தில், நான் கேமராவைப் பார்க்கிறேன்.நீங்கள் மிகவும் சக்திவாய்ந்த குரலைக் கொண்டிருக்க விரும்புகிறீர்கள், மிக முக்கியமாக, நீங்கள் பேசும் தலைப்புக்கு உற்சாகத்தைக் காட்ட விரும்புகிறீர்கள்.அனைவருக்கும் ஏய், இன்று நாங்கள் பொதுப் பேச்சைப் பற்றி பேசப் போகிறோம்.எனது பொது பேசும் திறனை வளர்க்க முடிந்த வெவ்வேறு வழிகளை நான் உங்களுக்கு கற்பிக்க விரும்புகிறேன்.\n",
      "\n",
      "--- Corrected Text ---\n",
      " \n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "from googletrans import Translator\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "\n",
    "# Load Whisper model\n",
    "model = whisper.load_model(\"medium\")\n",
    "translator = Translator()\n",
    "\n",
    "# Load T5 model for grammar correction (text improvement)\n",
    "t5_model = T5ForConditionalGeneration.from_pretrained(\"t5-base\")\n",
    "t5_tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")\n",
    "\n",
    "def extract_audio(video_path: str, output_audio: str = \"extracted_audio.wav\") -> str:\n",
    "    \"\"\"Extracts audio from a video file using FFmpeg.\"\"\"\n",
    "    command = [\n",
    "        \"ffmpeg\", \"-i\", video_path, \"-vn\", \"-acodec\", \"pcm_s16le\", \"-ar\", \"16000\", \"-ac\", \"1\", output_audio\n",
    "    ]\n",
    "    try:\n",
    "        subprocess.run(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, check=True)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error extracting audio: {e.stderr.decode()}\")\n",
    "        return None\n",
    "    \n",
    "    return output_audio\n",
    "\n",
    "def transcribe_audio(audio_path: str) -> str:\n",
    "    \"\"\"Transcribes speech from an audio file using Whisper AI.\"\"\"\n",
    "    result = model.transcribe(audio_path)\n",
    "    return result[\"text\"]\n",
    "\n",
    "def translate_text(text: str, target_language: str = 'ta') -> str:\n",
    "    \"\"\"Translates the transcribed text from English to the target language.\"\"\"\n",
    "    try:\n",
    "        translation = translator.translate(text, src='en', dest=target_language)\n",
    "        return translation.text\n",
    "    except Exception as e:\n",
    "        print(f\"Error translating text: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def correct_grammar(text: str) -> str:\n",
    "    \"\"\"Corrects grammatical issues using T5 (Text-to-Text Transfer Transformer).\"\"\"\n",
    "    # Preprocess the input text for grammar correction\n",
    "    input_text = f\"grammar correction: {text}\"\n",
    "    input_ids = t5_tokenizer.encode(input_text, return_tensors=\"pt\", truncation=True, padding=\"longest\")\n",
    "    \n",
    "    # Generate the corrected output using T5\n",
    "    output_ids = t5_model.generate(input_ids, max_length=512, num_beams=5, early_stopping=True)\n",
    "    \n",
    "    # Decode the corrected text\n",
    "    corrected_text = t5_tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "    return corrected_text\n",
    "\n",
    "def process_video(video_path: str, target_language: str):\n",
    "    \"\"\"Processes the video file: extracts audio, transcribes it, translates the text, and checks for grammar.\"\"\"\n",
    "    print(f\"Processing: {video_path}\")\n",
    "    \n",
    "    # Extract audio\n",
    "    audio_path = extract_audio(video_path, \"temp_audio1.wav\")\n",
    "    if not audio_path:\n",
    "        return\n",
    "    \n",
    "    # Transcribe\n",
    "    transcribed_text = transcribe_audio(audio_path)\n",
    "    \n",
    "    # Translate\n",
    "    translated_text = translate_text(transcribed_text, target_language)\n",
    "    \n",
    "    # Grammar check and correction on the translated text\n",
    "    corrected_text = correct_grammar(translated_text)\n",
    "    \n",
    "    # Cleanup\n",
    "    Path(audio_path).unlink(missing_ok=True)\n",
    "    \n",
    "    # Print the output\n",
    "    print(\"\\n--- Transcription ---\\n\", transcribed_text)\n",
    "    print(\"\\n--- Translated Text ---\\n\", translated_text)\n",
    "    print(\"\\n--- Corrected Text ---\\n\", corrected_text)\n",
    "\n",
    "\n",
    "# Example usage in Jupyter Notebook\n",
    "video_file_path = \"/home/aravinds/directory_env/video.mp4\"  # Change to your video file path\n",
    "target_lang = \"ta\"  # Hindi (Change this for different languages)\n",
    "\n",
    "process_video(video_file_path, target_lang)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46dabb52-d8a1-4a56-ad40-0b515f1c4093",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e142446-b1e5-49ca-b902-8a7d0c56063f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
